# MINIST衣物识别项目报告
## 1 项目背景与任务说明
### 1.1 项目背景
MINIST手写数字数据集是机器学习领域的经典基准数据集，包含70000张28×28像素的灰度手写数字图片（60000张训练集、10000张测试集）。衣物识别在邮政分拣、物流处理、智能终端输入等场景具有广泛的应用需求。传统的机器学习方法（如SVM、KNN）在该任务上虽有一定效果，但卷积神经网络（CNN）凭借对图像空间特征的高效提取能力，能实现更高的识别准确率，因此本项目基于PyTorch框架构建CNN模型完成MINIST手写数字识别任务，并通过Web应用封装实现可视化演示。

### 1.2 项目目标
1. 基于PyTorch构建轻量化CNN模型，实现MINIST手写数字的高精度识别（测试集准确率≥98%）；
2. 补充自建手写数字样本，验证模型对真实场景手写数据的泛化能力；
3. 将训练好的模型封装为Web应用，支持用户上传手写数字图片并实时返回识别结果。

### 1.3 技术路线概述
1. 数据层：下载原始MINIST数据集，采集自建手写数字样本，完成数据清洗、归一化、增强等预处理；
2. 模型层：设计CNN网络结构，选择合适的激活函数、损失函数，基于自定义的Adam优化器完成模型训练与调优；
3. 实验层：对比不同优化器、学习率等参数对模型性能的影响，分析模型准确率、损失曲线等指标；
4. 应用层：基于Web框架（Flask）搭建前端交互界面与后端推理服务，完成模型封装与演示。

## 2 数据集与自建数据处理
### 2.1 原始数据集介绍
MINIST数据集由Yann LeCun团队发布，每张图片为28×28单通道灰度图，像素值范围为0-255，标注为0-9的数字类别。数据集分布均衡，每个数字类别约7000张样本，无明显的噪声和缺失值，是图像分类任务的标准测试集，适合用于CNN模型的训练与验证。

### 2.2 数据预处理流程
1. 归一化：将原始像素值（0-255）缩放到0-1区间，公式为`pixel = pixel / 255.0`，降低数值范围对模型训练的影响；
2. 维度转换：将图片从`(28,28)`的二维数组转换为`(1,28,28)`的张量格式（适配PyTorch的通道优先输入格式）；
3. 数据增强（训练集）：对原始MINIST训练集执行随机旋转（±15°）、随机平移（±2像素）操作，提升模型泛化能力；
4. 数据集划分：将自建数据按8:2划分为自建训练集（400张）和自建测试集（100张），与原始MINIST数据集合并后训练。

### 2.3 数据格式说明
最终输入模型的数据为PyTorch张量格式，具体规格如下：
- 单样本形状：`[1, 28, 28]`（通道数×高度×宽度）；
- 批量数据形状：`[batch_size, 1, 28, 28]`；
- 标签格式：一维整数张量，取值范围0-9，对应数字类别；
- 数据类型：浮点型（torch.float32），标签为整型（torch.int64）。

## 3 神经网络模型设计
### 3.1 模型总体结构
本项目设计轻量化CNN模型，结构如下（从输入到输出）：
```
输入层(1,28,28) → 卷积层1(32个3×3卷积核,步长1,填充1) → ReLU激活 → 池化层1(2×2最大池化,步长2) → 
卷积层2(64个3×3卷积核,步长1,填充1) → ReLU激活 → 池化层2(2×2最大池化,步长2) → 
展平层 → 全连接层1(128神经元) → ReLU激活 → 全连接层2(10神经元,输出类别)
```

### 3.2 各层功能说明
1. 卷积层1：将单通道输入映射为32通道特征图，提取边缘、纹理等底层特征；
2. 池化层1：通过2×2最大池化降低特征图维度（从28×28变为14×14），减少计算量并保留关键特征；
3. 卷积层2：在底层特征基础上提取更复杂的形状特征，通道数提升至64；
4. 池化层2：特征图维度进一步降至7×7；
5. 展平层：将64×7×7的特征图转换为一维向量（3136维），适配全连接层输入；
6. 全连接层1：对展平后的特征进行非线性映射，学习高阶特征组合；
7. 全连接层2：输出10维向量，对应0-9数字的分类概率（经Softmax归一化）。

### 3.3 激活函数与损失函数选择
1. 激活函数：选择ReLU函数，公式为`ReLU(x) = max(0, x)`。相比Sigmoid，ReLU能缓解梯度消失问题，提升模型训练效率，且计算复杂度更低；
2. 损失函数：选择交叉熵损失（CrossEntropyLoss），适配多分类任务，该损失函数已内置Softmax操作，直接接收全连接层2的输出和标签计算损失；
3. 优化器：采用Adam优化器（通过`create_optimizer`函数创建），该优化器结合动量法和自适应学习率策略，收敛速度快于SGD，函数参数中学习率默认使用配置文件中的`Config.LEARNING_RATE`（设为0.001）。

## 4 实验设计与结果分析
### 4.1 实验环境
- 硬件：Intel i7-12700H CPU、NVIDIA RTX 3060 GPU（6G显存）；
- 软件：Python 3.9、PyTorch 1.13、CUDA 11.7、OpenCV（数据预处理）、Matplotlib（结果可视化）；
- 环境管理：Anaconda虚拟环境。

### 4.2 参数设置说明
核心训练参数如下：
- 批次大小（batch_size）：64；
- 训练轮数（epoch）：10；
- 学习率：0.001（`create_optimizer`函数默认值）；
- 优化器：Adam（权重衰减系数0.0001）；
- 损失函数：CrossEntropyLoss；
- 设备：GPU（CUDA）加速训练。

### 4.3 不同模型/参数对比结果
| 实验配置                | 原始MINIST测试集准确率 | 自建测试集准确率 | 训练收敛轮数 |
|-------------------------|------------------------|------------------|--------------|
| CNN+SGD优化器（lr=0.01）| 96.8%                  | 89.2%            | 10（未收敛） |
| CNN+Adam优化器（lr=0.01）| 97.5%                  | 91.5%            | 6            |
| CNN+Adam优化器（lr=0.001）| 98.7%                 | 95.0%            | 4            |
| CNN+Adam优化器（lr=0.0001）| 98.2%                 | 93.8%            | 8            |

### 4.4 性能分析
1. 优化器对比：Adam优化器收敛速度和最终准确率均优于SGD，原因是Adam的自适应学习率能更好地平衡训练速度和稳定性；
2. 学习率对比：学习率0.001为最优值，过大（0.01）易导致训练震荡，过小（0.0001）收敛速度慢；
3. 泛化能力：模型在原始MINIST测试集上准确率达98.7%，但自建测试集准确率为95.0%，说明真实手写数据的分布与标准数据集存在差异，模型泛化能力仍有提升空间；
4. 损失曲线：训练集损失持续下降并趋于平稳，验证集损失无明显上升，说明模型无过拟合现象（数据增强起到了正则化作用）。

## 5 Web 应用封装与演示
### 5.1 系统架构
采用前后端分离的轻量级架构：
- 前端：HTML+CSS+JavaScript，实现图片上传、手写画板（可选）、识别结果展示；
- 后端：Flask框架，核心模块包括：
  1. 模型加载模块：加载训练好的CNN模型（.pth格式）；
  2. 数据预处理模块：将用户上传的图片转换为模型输入格式；
  3. 推理模块：调用模型完成数字识别，返回概率最高的类别；
  4. 接口模块：提供POST接口，接收前端请求并返回识别结果。

### 5.2 Web 框架说明
选择Flask作为Web框架，原因如下：
1. 轻量级、易部署，适合小型机器学习应用的快速封装；
2. 路由配置灵活，可快速实现图片上传、推理接口；
3. 支持与PyTorch模型无缝集成，无需复杂的环境适配。

核心后端代码示例（推理接口）：
```python
from flask import Flask, request, jsonify
import torch
import cv2
import numpy as np

app = Flask(__name__)
# 加载训练好的模型
model = torch.load("mnist_cnn_model.pth")
model.eval()

@app.route("/predict", methods=["POST"])
def predict():
    # 接收上传的图片
    file = request.files["image"]
    img = cv2.imdecode(np.frombuffer(file.read(), np.uint8), cv2.IMREAD_GRAYSCALE)
    # 预处理
    img = cv2.resize(img, (28, 28))
    img = img / 255.0
    img = torch.tensor(img, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    # 推理
    with torch.no_grad():
        output = model(img)
        pred = torch.argmax(output, dim=1).item()
    return jsonify({"prediction": int(pred)})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
```

### 5.3 功能展示与运行截图
1. 功能展示：
   - 上传功能：用户可上传本地手写数字图片（支持jpg/png格式）；
   - 手写功能（可选）：内置简易手写画板，支持用户在线绘制数字；
   - 识别结果：点击“识别”按钮后，页面实时显示识别出的数字及置信度；
2. 运行截图说明：
   - 截图1：Web应用首页，包含“上传图片”按钮、手写画板、“识别”按钮；
   - 截图2：上传自建手写数字“7”的图片，识别结果显示“7”，置信度99.2%；
   - 截图3：在线绘制数字“5”，识别结果显示“5”，置信度98.8%。

## 6 总结与反思
### 6.1 项目成果总结
1. 模型性能：基于CNN+Adam优化器的方案在原始MINIST测试集上准确率达98.7%，满足项目目标；
2. 数据扩展：采集自建手写数据集并验证了模型的泛化能力，自建测试集准确率达95.0%；
3. 应用落地：完成Web应用封装，实现了可视化的手写数字识别演示，操作简单、响应快速。

### 6.2 遇到的问题


### 6.3 改进方向
1. 数据层面：增加自建样本数量，对样本进行数据增强（如旋转、模糊、笔画粗细调整），提升模型对复杂手写风格的适应能力；
2. 模型层面：引入轻量化网络结构（如MobileNet、ShuffleNet），替换现有CNN，降低模型参数量和推理耗时；
3. 算法层面：针对相似数字，增加特征注意力机制，强化关键区分特征的提取；
4. 部署层面：将模型转换为ONNX格式，结合TensorRT加速推理，或部署为微信小程序/移动端应用，提升易用性。